{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b02114",
   "metadata": {},
   "source": [
    "# Homework 02 - 19 September, 2024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba73642c",
   "metadata": {},
   "source": [
    "# 1. Monty Hall Problem - Python Simulation\n",
    "\n",
    "Q.1 ChatGPT Log: https://chatgpt.com/share/66ece617-e8e0-8008-af27-f7f1ce06bf1a\n",
    "\n",
    "Given a program simulating the Monty Hall scenario provided by Professor Schwartz, we ask ChatGPT to explain the code in its statistical and programming context in order to fully understand the problem and be able to analyze its results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42174371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66717"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code from Prof. Schwartz\n",
    "\n",
    "import numpy as np\n",
    "all_door_options = (1,2,3)  # tuple\n",
    "my_door_choice = 1  # 1,2,3\n",
    "i_won = 0\n",
    "reps = 100000\n",
    "for i in range(reps):\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "    all_door_options_list = list(all_door_options)\n",
    "    # take the secret_winning_door, so we don't show it as a \"goat\" losing door\n",
    "    all_door_options_list.remove(secret_winning_door)\n",
    "    try:\n",
    "        # if my_door_choice was secret_winning_door then it's already removed\n",
    "        all_door_options_list.remove(my_door_choice)\n",
    "    except:\n",
    "        pass\n",
    "    # show a \"goat\" losing door and remove it\n",
    "    goat_door_reveal = np.random.choice(all_door_options_list)\n",
    "    all_door_options_list.remove(goat_door_reveal)\n",
    "\n",
    "    # put the secret_winning_door back in if it wasn't our choice\n",
    "    # we previously removed it, so it would be shown as a  \"goat\" losing door\n",
    "    if secret_winning_door != my_door_choice:\n",
    "        all_door_options_list.append(secret_winning_door)\n",
    "    # if secret_winning_door was our choice then all that's left in the list is a \"goat\" losing door\n",
    "    # if secret_winning_door wasn't our choice then it's all that will be left in the list\n",
    "\n",
    "    # swap strategy\n",
    "    my_door_choice = all_door_options_list[0]\n",
    "\n",
    "    if my_door_choice == secret_winning_door:\n",
    "        i_won += 1\n",
    "\n",
    "i_won/reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7810d",
   "metadata": {},
   "source": [
    "## ChatGPT's Response (Summary):\n",
    "\n",
    "This code simulates the Monty Hall problem over 100,000 iterations to illustrate the probability of winning when always using the strategy of switching doors after a goat is revealed.\n",
    "\n",
    "1. **Initialization:**\n",
    "   - `all_door_options = (1, 2, 3)` defines the three doors in the game.\n",
    "   - The player always starts by choosing door 1 (`my_door_choice = 1`).\n",
    "   - `i_won = 0` keeps track of how many times the player wins, while `reps = 100,000` defines the number of trials.\n",
    "\n",
    "2. **Simulating a Single Game (Looped 100,000 Times):**\n",
    "   - A random winning door (`secret_winning_door = np.random.choice(all_door_options)`) is selected, representing where the car is hidden.\n",
    "   - A copy of the door list is created (`all_door_options_list = list(all_door_options)`) to allow for manipulation.\n",
    "   \n",
    "3. **Goat Door Removal:**\n",
    "   - The code removes the `secret_winning_door` from the list to ensure it won’t be selected as a goat door.\n",
    "   - It then tries to remove `my_door_choice` (the player's original choice of door 1). If door 1 was already the winning door, this removal is skipped using a `try-except` block.\n",
    "   \n",
    "4. **Revealing a Goat Door:**\n",
    "   - From the remaining doors (excluding the player’s choice and the winning door), the code randomly selects one as the \"goat door\" to reveal (`goat_door_reveal = np.random.choice(all_door_options_list)`).\n",
    "   - This simulates Monty Hall opening a door to show a goat. The goat door is then removed from the list.\n",
    "\n",
    "5. **Switching Strategy:**\n",
    "   - After the goat door is revealed, the player is left with one remaining unopened door. If the player’s original choice was not the winning door, the code adds the winning door back to the list (`all_door_options_list.append(secret_winning_door)`).\n",
    "   - The player then switches to the only remaining door (`my_door_choice = all_door_options_list[0]`), simulating the switching strategy.\n",
    "\n",
    "6. **Win Check:**\n",
    "   - After switching, the code checks if the player's new choice matches the winning door (`if my_door_choice == secret_winning_door`).\n",
    "   - If the player has won (i.e., chosen the door with the car), the win counter (`i_won`) is incremented.\n",
    "\n",
    "7. **Final Calculation:**\n",
    "   - Once the simulation runs through all 100,000 repetitions, the proportion of games won by switching is calculated (`i_won/reps`).\n",
    "   - This ratio approximates the probability of winning when following the switching strategy, which should be close to 2/3. This result reflects the theoretical outcome of the Monty Hall problem: switching doors significantly increases the player’s chances of winning compared to sticking with the original choice (which only wins 1/3 of the time).\n",
    "\n",
    "This simulation demonstrates the counterintuitive result that switching doors is the optimal strategy, and provides empirical evidence of the advantage through repeated trials.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa5da3f",
   "metadata": {},
   "source": [
    "# 2. Simplified For Loop\n",
    "\n",
    "Q.2 ChatGPT Log: https://chatgpt.com/share/66ece617-e8e0-8008-af27-f7f1ce06bf1a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a26352",
   "metadata": {},
   "source": [
    "When prompted to streamline the original code provided, ChatGPT preferred to use a list comprehension ( `[x for x in collection]` ). It utilized boolean comparisons within each comprehension in order to filter the elements of each list to the constrained conditions. <br><br>\n",
    "\n",
    "This decreases the amount if if statements and overall makes the code a lot cleaner. List comprehensions are a fairly beginner-friendly concept and an easy way to condense code into one readable line.\n",
    "\n",
    "Take the example of choosing a goat door:\n",
    "- Instead of looping over all doors and finding which one is neither the chosen door or the winning door, we make a list of all doors that satisfy these conditions and let numpy pick a random one from such a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825f164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66852"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy for random operations and define variables\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "all_door_options = (1, 2, 3)\n",
    "my_door_choice = 1\n",
    "i_won = 0\n",
    "reps = 100000\n",
    "\n",
    "for i in range(reps):\n",
    "    \n",
    "    # Use np to randomly choose a door to be the winner\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "    \n",
    "    ### Monty reveals a goat door that's neither the player's choice nor the winning door\n",
    "\n",
    "    # Possible doors to reveal from; will not be the winning door, nor will it be the chosen door\n",
    "    remaining_doors = [door for door in all_door_options if door != my_door_choice and door != secret_winning_door]\n",
    "    \n",
    "    # Choose a random goat door from the options defined above\n",
    "    goat_door_reveal = np.random.choice(remaining_doors)\n",
    "    \n",
    "    # Other available door that is unopened (Not the chosen door AND not the goat door)\n",
    "    other_available_doors = [door for door in all_door_options if door != my_door_choice and door != goat_door_reveal]\n",
    "    \n",
    "    # Switch to the other unopened door\n",
    "    switched_choice = other_available_doors[0]\n",
    "    \n",
    "    # Check if switching wins\n",
    "    if switched_choice == secret_winning_door:\n",
    "        i_won += 1\n",
    "\n",
    "# Calculate win rate (win rate = total wins / total attempts)\n",
    "i_won / reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09081e62",
   "metadata": {},
   "source": [
    "## ChatGPT Session Summary\n",
    "\n",
    "### Summary of Changes:\n",
    "\n",
    "1. **Simplified Logic:** \n",
    "   - Replaced the original door elimination process with direct list comprehensions to determine Monty’s reveal (`remaining_doors`) and the player's switch (`other_available_doors`).\n",
    "\n",
    "2. **Enhanced Readability:**\n",
    "   - Used descriptive variable names and split list comprehensions into two lines to improve clarity.\n",
    "\n",
    "### Final Code:\n",
    "The code efficiently simulates the Monty Hall problem by:\n",
    "- Randomly selecting a winning door.\n",
    "- Identifying a door Monty can reveal.\n",
    "- Switching the player's choice to the remaining door.\n",
    "- Calculating the win rate over 100,000 simulations using the switch strategy.\n",
    "\n",
    "These changes made the code more concise and easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4b933",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 3. Commented Final Code\n",
    "\n",
    "Q.3 ChatGPT Log: https://chatgpt.com/share/66ece617-e8e0-8008-af27-f7f1ce06bf1a\n",
    "\n",
    "Below is the final, modified code with comments to clarify each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04cf0ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the numpy library to use random functions and define key variables\n",
    "import numpy as np\n",
    "\n",
    "# Define the available doors (1, 2, 3) as a tuple\n",
    "all_door_options = (1, 2, 3)\n",
    "\n",
    "# The player always initially chooses door 1\n",
    "my_door_choice = 1\n",
    "\n",
    "# Initialize a counter to track the number of wins when switching\n",
    "i_won = 0\n",
    "\n",
    "# Define the number of repetitions (100,000 simulations)\n",
    "reps = 100000\n",
    "\n",
    "# Loop over the number of repetitions (simulate 100,000 rounds of the game)\n",
    "for i in range(reps):\n",
    "    \n",
    "    # Randomly select one door as the winning door (the door hiding the car)\n",
    "    secret_winning_door = np.random.choice(all_door_options)\n",
    "    \n",
    "    # Determine the doors Monty can reveal (neither the player's choice nor the winning door)\n",
    "    remaining_doors = [door for door in all_door_options if door != my_door_choice and door != secret_winning_door]\n",
    "    \n",
    "    # Monty randomly reveals one of the remaining goat doors\n",
    "    goat_door_reveal = np.random.choice(remaining_doors)\n",
    "    \n",
    "    # Determine the other unopened door (the door the player will switch to)\n",
    "    other_available_doors = [door for door in all_door_options if door != my_door_choice and door != goat_door_reveal]\n",
    "    \n",
    "    # Switch the player's choice to the remaining unopened door\n",
    "    switched_choice = other_available_doors[0]\n",
    "    \n",
    "    # Check if the switched choice is the winning door (if the player wins after switching)\n",
    "    if switched_choice == secret_winning_door:\n",
    "        # Increment the win counter if the player wins by switching\n",
    "        i_won += 1\n",
    "\n",
    "# Calculate the win rate by dividing the number of wins by the total number of repetitions\n",
    "i_won / reps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab10f600",
   "metadata": {},
   "source": [
    "## GPT Session Summary for Final Code\n",
    "\n",
    "### Summary of Session Discussions\n",
    "\n",
    "In this session, we focused on streamlining and improving the Monty Hall problem simulation code. Key points discussed include:\n",
    "\n",
    "1. **Code Streamlining:**\n",
    "   - Simplified door selection by using list comprehensions to filter out doors directly, eliminating unnecessary removal and re-addition of doors.\n",
    "   - Introduced descriptive variable names such as `remaining_doors` and `other_available_doors` for clarity.\n",
    "\n",
    "2. **Readability Improvements:**\n",
    "   - Split list comprehensions into two lines to enhance readability and make the filtering conditions clearer.\n",
    "   - Maintained a logical flow in the code to ensure it remains easy to follow.\n",
    "\n",
    "3. **Final Code Overview:**\n",
    "   - The final code efficiently simulates the Monty Hall problem by randomly selecting a winning door, identifying a goat door for Monty to reveal, switching the player’s choice to the remaining door, and calculating the win rate over 100,000 simulations.\n",
    "\n",
    "Overall, the session focused on creating a clearer, more efficient version of the Monty Hall simulation while ensuring it is educationally effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27569574",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "# 4. Markvoain Chat Bots\n",
    "\n",
    "Q.4 ChatGPT Log: https://chatgpt.com/share/66ecec34-5a0c-8008-b1fd-f65c5d578b84<br>\n",
    "(Refined Summary Log: https://chatgpt.com/share/66ecec51-dc40-8008-a43b-59cf7adeb194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d2f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markov Chains and Text Generation\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('56mGTszb_iM', width = 550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0942f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markovian Chatbot\n",
    "# from collections import defaultdict\n",
    "word_used = dict() # defaultdict(int)\n",
    "next_word = dict() # defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-1]):\n",
    "\n",
    "    if word in word_used:\n",
    "        word_used[word] += 1\n",
    "    else:\n",
    "        word_used[word] = 1\n",
    "        next_word[word] = {}\n",
    "\n",
    "    if words[i+1] in next_word[word]:\n",
    "        next_word[word][words[i+1]] += 1\n",
    "    else:\n",
    "        next_word[word][words[i+1]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97ced0",
   "metadata": {},
   "source": [
    "### Markovian Chatbot Code Summary\n",
    "\n",
    "The Markovian Chatbot code utilizes two dictionaries: \n",
    "1. word_used, which tracks the frequency of each word.\n",
    "2. next_word, which is a nested dictionary that takes a word and maps it to a dictionary of subsequent words and how frequently they appear:\n",
    "- { word in list: {subsequent word: frequency of subsequent word} }.\n",
    "\n",
    "\n",
    "\n",
    "### GPT's Response\n",
    "\n",
    "This code implements a Markovian chatbot that learns word transitions from a sequence of words.\n",
    "\n",
    "#### Key Variables\n",
    "- **word_used**: A dictionary counting each word's occurrences (not essential for functionality).\n",
    "- **next_word**: A nested dictionary where each key is a word, tracking how often each subsequent word follows it.\n",
    "\n",
    "#### Code Breakdown\n",
    "- **Loop Iteration (enumeration)**: Iterates through the words, treating each as the current word and checking the next.\n",
    "  \n",
    "- **Word Counting (word_used)**: Increments the count for existing words or initializes them with a count of 1.\n",
    "\n",
    "- **Next Word Counting (next_word)**: Tracks the frequency of the next word for each current word, incrementing counts or adding new entries.\n",
    "\n",
    "#### Key Insights\n",
    "- **Transition Frequencies**: Focuses on how often one word follows another, which is crucial for generating coherent sentences.\n",
    "  \n",
    "- **Word Frequencies**: Counts from `word_used` are secondary; the chatbot relies on transition probabilities from `next_word` for response generation.\n",
    "\n",
    "In summary, the chatbot's functionality hinges on word transitions, enabling it to predict the next word and maintain a natural flow in conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a5bf7",
   "metadata": {},
   "source": [
    "# 5. Markovian ChatBot Extensions\n",
    "\n",
    "Q.5 ChatGPT Logs: \n",
    "\n",
    "<br>\n",
    "\n",
    "- Q.5.1-5.2: https://chatgpt.com/share/66ecec34-5a0c-8008-b1fd-f65c5d578b84<br><br>\n",
    "- Q5.3 https://chatgpt.com/share/66ecee07-cbb4-8008-9ea1-cfe3ba18841a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f06f6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markovian Chatbot Extension #1\n",
    "\n",
    "word_used2 = defaultdict(int)\n",
    "next_word2 = defaultdict(lambda: defaultdict(int))\n",
    "for i,word in enumerate(words[:-2]):\n",
    "    word_used2[word+' '+words[i+1]] += 1\n",
    "    next_word2[word+' '+words[i+1]][words[i+2]] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c9c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markovian Chatbot Extension #2\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "# `avatar` is a dataset, and `character` is one of it's columns\n",
    "characters = Counter(\"\\n\"+ avatar.character.str.upper().str.replace(' ','.')+\":\")\n",
    "# this code changes the type of the `character` column to `str`; then,\n",
    "# makes the text uppercase, and replaces spaces with '.'\n",
    "\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "word_used2C = nested_dict()\n",
    "next_word2C = nested_dict()\n",
    "\n",
    "for i,word in enumerate(words[:-2]):\n",
    "    if word in characters:\n",
    "        character = word\n",
    "        \n",
    "    if character not in word_used2C:\n",
    "        word_used2C[character] = dict()\n",
    "    if word+' '+words[i+1] not in word_used2C[character]:\n",
    "        word_used2C[character][word+' '+words[i+1]] = 0\n",
    "    word_used2C[character][word+' '+words[i+1]] += 1\n",
    "    \n",
    "    if character not in next_word2C:\n",
    "        next_word2C[character] = dict()\n",
    "    if word+' '+words[i+1] not in next_word2C[character]:\n",
    "        next_word2C[character][word+' '+words[i+1]] = dict()\n",
    "    if words[i+2] not in next_word2C[character][word+' '+words[i+1]]:\n",
    "        next_word2C[character][word+' '+words[i+1]][words[i+2]] = 0\n",
    "    next_word2C[character][word+' '+words[i+1]][words[i+2]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884e0aa",
   "metadata": {},
   "source": [
    "## 1. GPT Understanding of Code Extensions\n",
    "\n",
    "When given extensions of the Markovian model of text generation, GPT **correctly** gives the following response when prompted to provide an explanation: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828ee9b",
   "metadata": {},
   "source": [
    "- ### What's Happening in Extension #1:\n",
    "\n",
    "1. **Bigrams instead of Unigrams**:\n",
    "   - Instead of using individual words (`unigrams`) to track word transitions, this extension uses **bigrams** (pairs of two consecutive words). This means that the current \"state\" in the Markov model is now a pair of words, not just one.\n",
    "   \n",
    "2. **Data Structures**:\n",
    "   - `word_used2`: This `defaultdict(int)` counts how often a particular **pair of words** (bigram) appears in the dataset.\n",
    "   - `next_word2`: This is a nested `defaultdict` that tracks how often a **third word** follows a specific bigram.\n",
    "   \n",
    "3. **Loop**:\n",
    "   - The loop iterates through the list `words` but stops at the third-to-last word (`words[:-2]`), ensuring that there are always two following words to create a bigram and a third word for the next step.\n",
    "   - For each iteration:\n",
    "     - The pair of words (`word + ' ' + words[i+1]`) is treated as a **single entity** (bigram).\n",
    "     - `word_used2[word + ' ' + words[i+1]]` tracks how many times this bigram appears.\n",
    "     - `next_word2[word + ' ' + words[i+1]][words[i+2]]` records how many times the third word (`words[i+2]`) follows the bigram.\n",
    "\n",
    "    #### Purpose of Extension #1:\n",
    "\n",
    "    This extension moves from a **first-order** Markov model (where the next word depends only on the current word) to a **second-order** Markov model, where the next word depends on the **previous two words**. This approach can provide more contextual accuracy by considering a broader history when predicting the next word, allowing for more natural and coherent responses in text generation.\n",
    "\n",
    "---\n",
    "\n",
    "- ### What's Happening in Extension #2:\n",
    "\n",
    "1. **Introduction of `character` Context**:\n",
    "   - This extension adds a character-based context to the Markov chain model. The `characters` variable processes the `avatar.character` column, converting each character's name to uppercase and replacing spaces with periods.\n",
    "   - The character name is treated as an identifier or marker in the chatbot’s dataset.\n",
    "\n",
    "2. **Nested `defaultdict` for Multiple Characters**:\n",
    "   - `nested_dict`: A function that returns a `defaultdict` of itself. This allows for deeply nested dictionaries, useful for organizing the data under multiple layers (e.g., characters → bigrams → next words).\n",
    "   - `word_used2C` and `next_word2C` are **character-specific dictionaries** where data is organized by character names.\n",
    "\n",
    "3. **Loop and Logic**:\n",
    "   - The loop iterates through the list of words (similar to Extension #1), but with an additional layer of character context:\n",
    "     - The first `if word in characters:` checks if the current word is a character's name. If so, the `character` variable is updated to that word, associating the bigram and next word with the current character.\n",
    "     - **For each character**:\n",
    "       - `word_used2C[character][word + ' ' + words[i+1]]` tracks how many times a bigram (pair of words) is used in that character's speech or dialogue.\n",
    "       - `next_word2C[character][word + ' ' + words[i+1]][words[i+2]]` records how often the third word follows a bigram, but specifically **under the character’s name**.\n",
    "\n",
    "    #### Purpose of Extension #2:\n",
    "\n",
    "    This extension allows the chatbot to differentiate between word transitions based on **character context**. It is useful in cases where the chatbot interacts with multiple personas or characters, and their speech patterns may differ. By tracking bigrams and next words for each character, the model can generate text that is more **character-specific**, adapting the language based on who is speaking.\n",
    "\n",
    "    ### Overall Goal:\n",
    "    Both extensions aim to add more complexity and context to the Markovian model:\n",
    "- **Extension #1**: Moves from a first-order to a second-order Markov model by considering bigrams.\n",
    "- **Extension #2**: Adds a character-specific dimension, allowing the model to differentiate speech patterns or word transitions for different characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457a32b",
   "metadata": {},
   "source": [
    "...Overall, GPT does an excellent job identifying the changes in the code and explaining them. It correctly pointed out that extension one looks two words ahead in making the dictionaries for each word used, essentially creating a pair of successive words for each word in a sequence. As GPT explained, this **bigram** model provides greater context and makes the generated text more sensible.\n",
    "\n",
    "GPT not only correctly identified that extension two also uses a bigram model, but also explained how it introduced additional context by tracking the character's bigram sequencing. This allows for character-specific dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254bc4a",
   "metadata": {},
   "source": [
    "## 2. Code Details\n",
    "\n",
    "While extension 1 was fairly straight forward, extension 2 was still confusing, so I prompted GPT with some questions, specifically how bigrams are stored under character-specific dictionaries. Below is a summary of the dialogue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136436ca",
   "metadata": {},
   "source": [
    "### Session Summary: Understanding Extension 2 of the Markovian Chatbot\n",
    "\n",
    "In this session, we delved into **Extension 2** of the Markovian chatbot, which enhances the model by adding **character-specific bigram chains**. The goal of this extension is to track how words are used by each character independently, allowing the chatbot to generate personalized and contextually accurate dialogue for multiple personas.\n",
    "\n",
    "#### Key Features of Extension 2:\n",
    "\n",
    "1. **Character Identification**:\n",
    "   - The model recognizes when a character's name appears in the text by referencing a dataset (`characters`). When it encounters a character name, it updates the context to reflect that character, indicating that subsequent words should be tracked as part of that character’s dialogue.\n",
    "\n",
    "2. **Bigram Chains for Each Character**:\n",
    "   - After identifying a character, the model begins forming **bigrams** (pairs of consecutive words) from their speech. The model records how often each bigram occurs in **`word_used2C`** and tracks what the next word is after each bigram in **`next_word2C`**.\n",
    "   - This forms a **second-order Markov chain** for each character, allowing the chatbot to predict the third word based on the previous two words spoken by that specific character. The word transitions are stored separately for each character, meaning that the model maintains independent chains for every speaker.\n",
    "\n",
    "3. **Tracking New Bigrams**:\n",
    "   - As the text progresses, each new bigram (two consecutive words) generates a new entry for the character’s chain. The third word that follows the bigram is then tracked under that character’s data. This continues for all word sequences spoken by the character until another character is introduced.\n",
    "\n",
    "4. **Switching Between Characters**:\n",
    "   - When a new character’s name appears in the text, the context **resets** to that new character, and the process starts over. The model begins creating a new bigram chain for the new character, keeping the word transitions distinct between speakers. This ensures that each character’s speech patterns are captured independently, preserving their unique dialogue style.\n",
    "\n",
    "#### Example Walkthrough:\n",
    "We worked through an example using the text `\"BOBBY: Hi, I like to play basketball. JOE: So do I.\"` to illustrate how the chatbot tracks character-specific bigrams.\n",
    "\n",
    "- For **BOBBY**, the model identified bigrams like:\n",
    "  - `\"Hi I\" → \"like\"`\n",
    "  - `\"I like\" → \"to\"`\n",
    "  - `\"like to\" → \"play\"`\n",
    "  - `\"to play\" → \"basketball\"`\n",
    "\n",
    "- When **JOE** started speaking, the model switched context and recorded a new bigram chain for him:\n",
    "  - `\"So do\" → \"I\"`\n",
    "\n",
    "This process shows how Extension 2 allows the chatbot to generate responses based on character-specific dialogue sequences, making the chatbot character-aware and capable of producing more natural and relevant responses based on the unique speech patterns of each individual character.\n",
    "\n",
    "### Conclusion:\n",
    "Extension 2 transforms the Markovian chatbot by creating distinct **bigram chains** for each character in the dataset. This extension improves the chatbot’s ability to generate more personalized and contextually relevant dialogue by ensuring that word transitions are tracked separately for each character. By switching contexts when a new character speaks, the model maintains separate chains, ensuring that each speaker's unique word patterns are accurately represented in future text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5f8dd",
   "metadata": {},
   "source": [
    "## 3. GPT Experiment: Complex Extension Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3590d03",
   "metadata": {},
   "source": [
    "Getting ChatGPT to accurately provide an explanation of Extension 2 was far more difficult than expected. It took approximately 15 minutes of back-and-forth dialogue, including hinting the ChatBot, for it to finally understand the purpose of the model. The session summary below, provided by the ChatBot, explains misconceptions, misunderstandings, and finally, realizations of the code's purpose:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e595685",
   "metadata": {},
   "source": [
    "### Summary of the Session\n",
    "\n",
    "#### Initial Confusion\n",
    "\n",
    "1. **Trigrams vs. Bigrams**:\n",
    "   - **Misunderstanding**: Initially, there was confusion about whether the code was handling trigrams or bigrams. Trigrams involve a sequence of three words, while bigrams involve two-word sequences.\n",
    "   - **Clarification**: It was established that the code was not handling trigrams but was focused on tracking bigrams and their subsequent words (to ensure .\n",
    "\n",
    "2. **Character Count and Filtering**:\n",
    "   - **Misinterpretation**: There was an initial misinterpretation regarding the role of the `characters` Counter, which was thought to be for filtering or processing data.\n",
    "   - **Clarification**: The correct role was identified as helping to manage and differentiate dialogue contexts for each character.\n",
    "\n",
    "3. **Code Purpose and Structure**:\n",
    "   - **Initial Misunderstanding**: The purpose of tracking next words and character-specific transitions was not clear. The focus was mistakenly on whether the code tracked trigrams, rather than understanding its true function.\n",
    "\n",
    "#### Correct Understanding of the Code\n",
    "\n",
    "1. **Purpose of the `characters` Counter**:\n",
    "   - **Role**: Prepares a list of characters and their unique identifiers (e.g., `\"JANE:\"`, `\"JOHN:\"`) for accurate dialogue management.\n",
    "   - **Usage**: Helps in managing character-specific contexts by distinguishing which character is speaking.\n",
    "\n",
    "2. **Bigram Tracking (`word_used2C`)**:\n",
    "   - **Function**: Tracks occurrences of bigrams (sequences of two words) within each character’s dialogue.\n",
    "   - **Purpose**: Allows for capturing how often specific word pairs occur in each character’s speech.\n",
    "\n",
    "3. **Tracking Next Words (`next_word2C`)**:\n",
    "   - **Function**: Records which words follow a given bigram within each character’s dialogue.\n",
    "   - **Purpose**: Enables the chatbot to predict and manage transitions from one bigram to the next word, while also handling cases where the next word might be a character.\n",
    "\n",
    "4. **Character-Specific Contexts**:\n",
    "   - **Separation**: By keeping bigrams and transitions separate for each character, the code ensures accurate representation of each character’s unique dialogue patterns.\n",
    "   - **Benefit**: This separation maintains the authenticity of dialogue and reflects each character’s individual style, vocabulary, and cadence.\n",
    "\n",
    "#### Final Realization\n",
    "\n",
    "- **Actual Purpose of the Code**: The code tracks character-specific bigrams and transitions. It maintains separate models for each character to ensure that the chatbot can generate dialogue that accurately reflects each character’s unique speech patterns and interactions. The separation of dictionaries for each character helps in managing and generating contextually appropriate responses based on character-specific dialogue data.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a0289",
   "metadata": {},
   "source": [
    "# 6.  ChatBot Effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907aa0d0",
   "metadata": {},
   "source": [
    "- ## 1. ChatBot Helpfullness for Homework 02\n",
    "\n",
    "    Overall, ChatGPT was extremely helpful in the above questions. Throughout this homework set, most of my experiences with GPT were used as supplementary guidance only after I explored the question myself.\n",
    "\n",
    "    For example, I didn't quite understand how the Monty Hall simulation code actually functioned during my tutorial, even after the ChatBot demos. It was only after playing around with the code myself and asking GPT for clarification that I understood the code and how it related to the problem's statistical basis. \n",
    "\n",
    "    The same sentiment followed for the Markovian ChatBot code. I understood the foundation and basics of the code from lecture, but ChatGPT helped support my comprehension and clear up confusion, as shown in the previous session summaries. The only issue I faced with GPT was on Q. 5.3, where it was difficult for it to make the direct jump towards the complex extension of the Markovian model. However, every other question that required a ChatBot session was helpful and reliable\n",
    "\n",
    "    Most importantly, GPT provided this help quickly. I probably could have found sufficient solutions through Piazza, tutors, or online forums, but GPT facilitates this help in an easy, quick manner. Of course, not everything GPT says is factual (although it is usually accurate), so I do confirm my results with my own experimentation, understanding, and research online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ec492",
   "metadata": {},
   "source": [
    "- ## 2. ChatBot User Experience\n",
    "\n",
    "    In my experience, the only frustration occurred during Q 5.3, as explained earlier, where ChatGPT failed to correctly interpret Extension 2 of the Markovian ChatBot Model. More specifically, it could not identify the bigram model and chracter-specific model at the same time, although it could explain each of this when introduced in succession. A fair amount of back-and-forth with the ChatBot was required before it understood what the code was trying to accomplish.\n",
    "\n",
    "    At the same time, I cannot deem this as unhelpful, as it seems that question was structured around showing the limitations of GPT in making large steps between code complexity; as well, the same explanation was correctly addressed in Q 5.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff9b1d",
   "metadata": {},
   "source": [
    "- ## 3. Overall Assessment of ChatBots in STA130\n",
    "\n",
    "    I have had an overall net positive experience with ChatBots in this course. While there are risks in becoming too dependant on ChatBots, I feel the way this course is structured has made them beneficial, especially in introductory-level Statistics. That is, rather than being overly occupied in the syntax, semantics, and demands of programming in Python, I have been able to use ChatGPT as a supplemental source for programming so that I can truly understand the statistical relevance in each problem or concept.\n",
    "\n",
    "    Additionally, GPT has been a quick, reliable source for re-explaining or filling in the gaps of certain topics covered in lectures and/or tutorials, such as survivorship bias.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df8768",
   "metadata": {},
   "source": [
    "# 7. ChatBot Reflection in STA130\n",
    "\n",
    "Throughout the first two weeks of this course, I found the ChatBots to be a helpful tool in supplementing information, whether it be purely Statistical or related to programming. As mentioned in Q.6, what I find most beneficial is the way this course is structured around ChatBots; prompts that are too general might not provide a sufficient response. Thus some level of prior knowledge is required before asking a question. This practice has reduced my sole reliance on the ChatBot as I must at least gain some surface-level knowledge of the code and what it is trying to accomplish before proceeding with a prompt. \n",
    "\n",
    "Additionally, when mentioned that a given prompt is intended for an assignment, the ChatBot gives a step-by-step detailed analysis that makes it increasingly easy for the user to reference and comprehend. Since utilizing these tools in this course, I've not only grown my own Statistical foundation of knowledge, but I've learned to use the resources given to me in order to maximize my own growth. Among this came the ability to leverage  ChatBots in order to apply Statistical models in Python. For example, asking ChatGPT to give me a pre-lecture report on Markovian models of text generation helped me to experiment with these models, preparing me for the discussions to be had in class.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b1d47",
   "metadata": {},
   "source": [
    "# 8. ChatBot Awareness and Application\n",
    "\n",
    "Q.8 ChatGPT Log: https://chatgpt.com/share/66ece4ca-3254-8008-b9d1-8da1c898df13\n",
    "\n",
    "## 1 - 3. ChatBot Discussions\n",
    "\n",
    "\n",
    "### **Summary of the Session**\n",
    "\n",
    "#### **1. Relevance of Key Skills in the Modern World**\n",
    "\n",
    "- **Learning and Adaptability:** These are crucial for staying competitive in the fast-paced tech industry, especially in data science, where new tools and methodologies constantly emerge. Being adaptable allows professionals to quickly learn new skills and apply them to solve complex problems.\n",
    "\n",
    "- **Communication:** In data science, the ability to effectively communicate insights and technical details to non-technical stakeholders is vital. It ensures that data-driven recommendations are understood and acted upon, aligning technical work with business objectives.\n",
    "\n",
    "- **Coding:** Coding is fundamental in data science for developing algorithms, automating processes, and handling large datasets. Proficiency in languages like Python or R is often a baseline requirement for most roles in the industry.\n",
    "\n",
    "- **Statistics & Data Analysis:** These are core to data science, enabling professionals to interpret data, build predictive models, and make informed decisions. A strong foundation in statistical methods is essential for creating robust analyses and ensuring the accuracy of insights.\n",
    "\n",
    "#### **2. Can You Be a Statistician or Data Scientist Without Coding or Data Analysis?**\n",
    "\n",
    "- **Possibility Without Coding:** While traditional statistical roles might not require extensive coding, they often involve using software tools like SPSS or SAS. However, for more advanced analyses or roles in data science, coding becomes increasingly important.\n",
    "\n",
    "- **Possibility Without Data Analysis:** A career as a statistician or data scientist fundamentally revolves around data analysis. It would be challenging to pursue these roles without engaging in data analysis, as interpreting data is central to the profession.\n",
    "\n",
    "### **Transition to Career Exploration**\n",
    "\n",
    "When considering a career in data science or software engineering, particularly with a Statistics + CS double major, identifying key skills that set you apart is essential. For example, combining deep statistical knowledge with software development can make you versatile across various industries, from finance to technology. \n",
    "\n",
    "For a **Software Engineer (SWE)**, focus on developing strong programming skills, understanding software engineering principles, and possibly exploring machine learning if it aligns with your interests. If your career interest leans more toward **Data Science**, mastering statistical modeling, data visualization, and machine learning would be highly valuable.\n",
    "\n",
    "In both cases, leveraging your dual expertise in statistics and computer science will enhance your problem-solving capabilities and make you a more competitive candidate in your chosen field."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52929a78",
   "metadata": {},
   "source": [
    "## 4. Paraphrased Summary of Discussion\n",
    "\n",
    "One of the most important pieces of advice I'd recieved from my brother who is a Software Engineer is that, when considering my goals, I should not think about where I can go from my current position, but that I should work backward from my goal and decide what steps I need to take to accomplish it. While I have a long ways to go before working in industry, I currently would like to have a future in Software Engineering. My first step towards this goal is to declare my POSt at the end of this school year as a double major in Computer Science and Statistics, granted that my GPA favour this.\n",
    "\n",
    "Paired with Computer Science, Statistics will not only expand my range of problem-solving abilities, but also open the door to positions in Machine Learning or Data Analytics, as ChatGPT mentioned. I am a firm believer that the best Engineers/Developers are not always the best coders, but rather the best communicators and problem solvers. However, as ChatGPT emphasizes, **coding is still a necessity** in any of the aforementioned fields. While Data Analysis and Software Engineering require problem-solving skills at their core, programming is still a baseline skill that I would need in order to even get my foot in the door of any of these positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869fecdb",
   "metadata": {},
   "source": [
    "## 5. On Career Advice from ChatBots\n",
    "\n",
    "ChatGPT often echoes a sentiment that is agreeable and obvious; it makes statements that are fundamentally true, but are somewhat obvious. For example, GPT claims a Software Engineer prospect should \"focus on developing strong programming skills\" and \"understanding software engineering principles\"; great insight, GPT!  \n",
    "\n",
    "What I look for in career advice is someone who is experienced in the relevant field and is able to provide insights that not any ordinary person could provide. This is where I would turn to a mentor like my brother to give me adivce on expectations in the workplace and the industry standard for job-searching. \n",
    "\n",
    "ChatGPT is a great general tutor, but is no where near as qualified as an expert on topics like these, which makes it even more important to avoid relying so much on GPT; the best way to expose yourself to specific, detailed explanations of subject matter like careers is to find a mentor or any expert who can explain the ins-and-outs to you. Additionally, GPT being trained on old data doesn't help for such a volatile field like Software Engineering (at least true for the high-paying, stress-enducing jobs).\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a513e",
   "metadata": {},
   "source": [
    "# 9. Resources Used\n",
    "\n",
    "Yes, I did review the course wiki-textbook, and I have interacted wiht a ChatBot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
